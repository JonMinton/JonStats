{"title":"A brief introduction to bootstrapping","markdown":{"yaml":{"title":"A brief introduction to bootstrapping","subtitle":"(It's only literally like pulling teeth, and only in this specific example!)","author":"Jon Minton","date":"2024-06-28","resampling-order":2,"categories":["bootstrapping","statistics","non-parametric"]},"headingText":"What is bootstrapping?","containsRefs":false,"markdown":"\n\nI met with [Neil Pettinger](https://www.kurtosis.co.uk/about/index.html) earlier today. He traded eggs benedict for some statistical advice, mainly on what bootstrapping is, and whether it could be helpful for analysing hospital length of stay data. \n\nHere's a brief post on bootstrapping with some example code:\n\n\nAccording to [Wikipedia](https://en.wikipedia.org/wiki/Bootstrapping_(statistics)): \n\n> Bootstrapping is any test or metric that uses random sampling with replacement (e.g. mimicking the sampling process), and falls under the broader class of resampling methods. Bootstrapping assigns measures of accuracy (bias, variance, confidence intervals, prediction error, etc.) to sample estimates.[1][2] This technique allows estimation of the sampling distribution of almost any statistic using random sampling methods.[3][4]\n\n> Bootstrapping estimates the properties of an estimand (such as its variance) by measuring those properties when sampling from an approximating distribution. One standard choice for an approximating distribution is the empirical distribution function of the observed data. In the case where a set of observations can be assumed to be from an independent and identically distributed population, this can be implemented by constructing a number of resamples with replacement, of the observed data set (and of equal size to the observed data set).\n\n> It may also be used for constructing hypothesis tests.[5] It is often used as an alternative to statistical inference based on the assumption of a parametric model when that assumption is in doubt, or where parametric inference is impossible or requires complicated formulas for the calculation of standard errors.\n\nn.b. The same page (In **History**) also states: \"Other names ... suggested for the 'bootstrap' method were: *Swiss Army Knife*, *Meat Axe*, *Swan-Dive*, *Jack-Rabbit*, and *Shotgun*.\" So, there might not be good reasons to fear statistics, but given this list of suggestions there might be good reasons to fear some statisticians! Of these alternative names, perhaps *Swiss Army Knife* is the most appropriate, as it's a very widely applicable approach! \n\n## A brief example\n\nI'm not going to look for length-of-stay data; instead I'm going to look at *length-of-teeth*, and the hamster experiment dataset I used in [a few previous posts](../../complete-simulation-example/lms-are-glms-part-11/index.qmd).\n\n```{r}\nlibrary(tidyverse)\ndf <- ToothGrowth |> tibble()\ndf\n\n```\n\nLet's say, instead of building a statistical model, I'm just interested in the following question:\n\n> Where the dose is 1mg, is using the OJ supplement instead of the VC supplement associated with a significant and detectable difference in the *median* tooth length? \n\nWe can do this in at least a couple of ways: \n\n1. Calculate the median of OJ at 1mg tooth lengths, and compare it to a bootstrapped distribution of medians from VC at 1mg. \n2. Bootstrap both the OJ and VC (both at 1mg) populations, get the medians for each bootstrapped population, and record the difference in the medians.\n\nThese are asking slightly different questions, but both ways of using bootstrapping to address the general type of question framed above. \n\n### Approach One\n\n```{r}\nNreps <- 10000 # Number of bootstrap replicates\n\nbs_med_vc <- vector(mode = 'numeric',  length = Nreps) #Vector for holding bootstrapped medians\n\ndta_vc <- df |>\n    filter(supp == \"VC\", dose == 1.0) # The equivalent of our 'control' population\n\ncontrol_toothlengths <- dta_vc |> pull(len) # Literally pulling teeth!\n\nNcontrol <- length(control_toothlengths) #Length of 'control' population sample\n\nfor (i in 1:Nreps){\n    bs_c_length <- sample(\n        control_toothlengths, \n        size = Ncontrol,\n        replace = TRUE\n    ) # resampling to the same length as the 'control' population\n\n    this_bs_control_median <- median(bs_c_length)\n    bs_med_vc[i] <- this_bs_control_median\n}\n```\n\nWe've now done the bootstrapping on the 'control' population. Let's look at this bootstrapped distribution of medians in comparison with the observed median from the 'treatment' group.\n\n```{r}\ntreatment_toothlengths <- df |>\n    filter(supp == \"OJ\", dose == 1.0) |>\n    pull(len) # pulling teeth for the 'treatment' population\n\nobs_med_oj <- median(treatment_toothlengths)\n\ntibble(bs_control_median = bs_med_vc) |>\n    ggplot(aes(x=bs_control_median)) +\n    geom_histogram() +\n    geom_vline(xintercept = obs_med_oj, colour = \"red\", linetype = \"dashed\") + \n    geom_vline(xintercept = median(control_toothlengths), colour = \"blue\", linetype = \"dashed\") + \n    labs(\n       x = \"Median toothlength\",\n       y = \"Number of bootstraps\",\n       title = \"Bootstrapping approach One\",\n       subtitle = \"Red line: Observed median toothlength in 'treatment' arm. Blue line: Observed median in 'control' arm\"\n    )\n\n```\n\nWe can see here that the red line, which is the observed median in the 'treatment' arm, is higher than all of the bootstrapped medians from the 'control' arm. The blue line shows the equivalent in the observed median in the 'control' arm. \n\nSo, without even performing a calculation, we can feel more confident that the OJ supplement is associated with larger tooth length, even though both arms comprise just ten observations. \n\n## Approach Two\n\nLet's now use bootstrapping to produce a distributions of differences in medians between the two arms. So, this time we repeatedly resample from both the control and the treatment arm.\n\n\n```{r}\nNreps <- 10000 # Number of bootstrap replicates\n\nbs_diff_meds <- vector(mode = 'numeric',  length = Nreps) #Vector for holding differences in bootstrapped medians\n\ndta_vc <- df |>\n    filter(supp == \"VC\", dose == 1.0) # The equivalent of our 'control' population\n\ncontrol_toothlengths <- dta_vc |> pull(len) # Literally pulling teeth!\n\nNcontrol <- length(control_toothlengths) #Length of 'control' population sample\n\ndta_oj <- df |>\n    filter(supp == \"OJ\", dose == 1.0) # The equivalent of our 'treamtnet' population\n\ntreatment_toothlengths <- dta_oj |> pull(len) # Literally pulling teeth!\n\nNtreatment <- length(treatment_toothlengths) #Length of 'treatment' population sample\n\n\nfor (i in 1:Nreps){\n    bs_c_length <- sample(\n        control_toothlengths, \n        size = Ncontrol,\n        replace = TRUE\n    ) # resampling to the same length as the 'control' population\n\n    this_bs_control_median <- median(bs_c_length)\n\n    bs_t_length <- sample(\n        treatment_toothlengths, \n        size = Ntreatment,\n        replace = TRUE\n    ) # resampling to the same length as the 'control' population\n\n    this_bs_treat_median <- median(bs_t_length)\n\n    bs_diff_meds[i] <- this_bs_treat_median - this_bs_control_median\n}\n\n```\n\nWe now have a bootstrapped distribution of differences, each time subtracting the bootstrapped control median from the bootstrapped treat median. So, values above 0 indicate the treatment is more effective (at lengthening teeth) than the control. \n\nLet's look at this distribution\n\n\n```{r}\ntibble(bs_diffs_median = bs_diff_meds) |>\n    ggplot(aes(x=bs_diffs_median)) +\n    geom_histogram() +\n    geom_vline(xintercept = 0) + \n    geom_vline(\n        xintercept = median(treatment_toothlengths) - median(control_toothlengths), linetype = \"dashed\", colour = \"green\"         \n        ) + \n    labs(\n       x = \"Differences in medians\",\n       y = \"Number of bootstraps\",\n       title = \"Bootstrapping approach Two\",\n       subtitle = \"Values above 0: medians are higher in treatment group\"\n    )\n\n```\n\nI've added the observed difference in medians as a vertical green line. This corresponds with the highest peak in bootstrapped differences in medians, as we might expect. \n\n*Almost* all bootstrapped differences in medians are above 0, which again suggests we don't even need to calculate the proportion above 0 to work out if there is likely to be a difference in medians between the two groups. \n\nHowever if we wanted to get this empirical p-value, we could do it as follows: \n\n```{r}\nsum(bs_diff_meds < 0) / Nreps\n\n```\n\nTiny! \n\n\n## Going further \n\nI suggested to Neil that writing some R code to do the bootstrapping can be a 'good' learning experience. This is what I've done in the above, using for loops as they're easiest to reason through, even though not the most computationally efficient. Once the intuition of what bootstrapping is, how it works, and what it can do is embedded through writing out a few examples like this, there are plenty of packages that make bootstrapping even easier to do (and likely faster to run too). \n\nI also mentioned and can (for pedagogic purposes) recommend [the infer package](https://infer.netlify.app/), which uses bootstrapping to produce estimates of distributions under the Null hypothesis, alongside parametric approaches, and produces pretty visualisations to boot! \n\n","srcMarkdownNoYaml":"\n\nI met with [Neil Pettinger](https://www.kurtosis.co.uk/about/index.html) earlier today. He traded eggs benedict for some statistical advice, mainly on what bootstrapping is, and whether it could be helpful for analysing hospital length of stay data. \n\nHere's a brief post on bootstrapping with some example code:\n\n## What is bootstrapping? \n\nAccording to [Wikipedia](https://en.wikipedia.org/wiki/Bootstrapping_(statistics)): \n\n> Bootstrapping is any test or metric that uses random sampling with replacement (e.g. mimicking the sampling process), and falls under the broader class of resampling methods. Bootstrapping assigns measures of accuracy (bias, variance, confidence intervals, prediction error, etc.) to sample estimates.[1][2] This technique allows estimation of the sampling distribution of almost any statistic using random sampling methods.[3][4]\n\n> Bootstrapping estimates the properties of an estimand (such as its variance) by measuring those properties when sampling from an approximating distribution. One standard choice for an approximating distribution is the empirical distribution function of the observed data. In the case where a set of observations can be assumed to be from an independent and identically distributed population, this can be implemented by constructing a number of resamples with replacement, of the observed data set (and of equal size to the observed data set).\n\n> It may also be used for constructing hypothesis tests.[5] It is often used as an alternative to statistical inference based on the assumption of a parametric model when that assumption is in doubt, or where parametric inference is impossible or requires complicated formulas for the calculation of standard errors.\n\nn.b. The same page (In **History**) also states: \"Other names ... suggested for the 'bootstrap' method were: *Swiss Army Knife*, *Meat Axe*, *Swan-Dive*, *Jack-Rabbit*, and *Shotgun*.\" So, there might not be good reasons to fear statistics, but given this list of suggestions there might be good reasons to fear some statisticians! Of these alternative names, perhaps *Swiss Army Knife* is the most appropriate, as it's a very widely applicable approach! \n\n## A brief example\n\nI'm not going to look for length-of-stay data; instead I'm going to look at *length-of-teeth*, and the hamster experiment dataset I used in [a few previous posts](../../complete-simulation-example/lms-are-glms-part-11/index.qmd).\n\n```{r}\nlibrary(tidyverse)\ndf <- ToothGrowth |> tibble()\ndf\n\n```\n\nLet's say, instead of building a statistical model, I'm just interested in the following question:\n\n> Where the dose is 1mg, is using the OJ supplement instead of the VC supplement associated with a significant and detectable difference in the *median* tooth length? \n\nWe can do this in at least a couple of ways: \n\n1. Calculate the median of OJ at 1mg tooth lengths, and compare it to a bootstrapped distribution of medians from VC at 1mg. \n2. Bootstrap both the OJ and VC (both at 1mg) populations, get the medians for each bootstrapped population, and record the difference in the medians.\n\nThese are asking slightly different questions, but both ways of using bootstrapping to address the general type of question framed above. \n\n### Approach One\n\n```{r}\nNreps <- 10000 # Number of bootstrap replicates\n\nbs_med_vc <- vector(mode = 'numeric',  length = Nreps) #Vector for holding bootstrapped medians\n\ndta_vc <- df |>\n    filter(supp == \"VC\", dose == 1.0) # The equivalent of our 'control' population\n\ncontrol_toothlengths <- dta_vc |> pull(len) # Literally pulling teeth!\n\nNcontrol <- length(control_toothlengths) #Length of 'control' population sample\n\nfor (i in 1:Nreps){\n    bs_c_length <- sample(\n        control_toothlengths, \n        size = Ncontrol,\n        replace = TRUE\n    ) # resampling to the same length as the 'control' population\n\n    this_bs_control_median <- median(bs_c_length)\n    bs_med_vc[i] <- this_bs_control_median\n}\n```\n\nWe've now done the bootstrapping on the 'control' population. Let's look at this bootstrapped distribution of medians in comparison with the observed median from the 'treatment' group.\n\n```{r}\ntreatment_toothlengths <- df |>\n    filter(supp == \"OJ\", dose == 1.0) |>\n    pull(len) # pulling teeth for the 'treatment' population\n\nobs_med_oj <- median(treatment_toothlengths)\n\ntibble(bs_control_median = bs_med_vc) |>\n    ggplot(aes(x=bs_control_median)) +\n    geom_histogram() +\n    geom_vline(xintercept = obs_med_oj, colour = \"red\", linetype = \"dashed\") + \n    geom_vline(xintercept = median(control_toothlengths), colour = \"blue\", linetype = \"dashed\") + \n    labs(\n       x = \"Median toothlength\",\n       y = \"Number of bootstraps\",\n       title = \"Bootstrapping approach One\",\n       subtitle = \"Red line: Observed median toothlength in 'treatment' arm. Blue line: Observed median in 'control' arm\"\n    )\n\n```\n\nWe can see here that the red line, which is the observed median in the 'treatment' arm, is higher than all of the bootstrapped medians from the 'control' arm. The blue line shows the equivalent in the observed median in the 'control' arm. \n\nSo, without even performing a calculation, we can feel more confident that the OJ supplement is associated with larger tooth length, even though both arms comprise just ten observations. \n\n## Approach Two\n\nLet's now use bootstrapping to produce a distributions of differences in medians between the two arms. So, this time we repeatedly resample from both the control and the treatment arm.\n\n\n```{r}\nNreps <- 10000 # Number of bootstrap replicates\n\nbs_diff_meds <- vector(mode = 'numeric',  length = Nreps) #Vector for holding differences in bootstrapped medians\n\ndta_vc <- df |>\n    filter(supp == \"VC\", dose == 1.0) # The equivalent of our 'control' population\n\ncontrol_toothlengths <- dta_vc |> pull(len) # Literally pulling teeth!\n\nNcontrol <- length(control_toothlengths) #Length of 'control' population sample\n\ndta_oj <- df |>\n    filter(supp == \"OJ\", dose == 1.0) # The equivalent of our 'treamtnet' population\n\ntreatment_toothlengths <- dta_oj |> pull(len) # Literally pulling teeth!\n\nNtreatment <- length(treatment_toothlengths) #Length of 'treatment' population sample\n\n\nfor (i in 1:Nreps){\n    bs_c_length <- sample(\n        control_toothlengths, \n        size = Ncontrol,\n        replace = TRUE\n    ) # resampling to the same length as the 'control' population\n\n    this_bs_control_median <- median(bs_c_length)\n\n    bs_t_length <- sample(\n        treatment_toothlengths, \n        size = Ntreatment,\n        replace = TRUE\n    ) # resampling to the same length as the 'control' population\n\n    this_bs_treat_median <- median(bs_t_length)\n\n    bs_diff_meds[i] <- this_bs_treat_median - this_bs_control_median\n}\n\n```\n\nWe now have a bootstrapped distribution of differences, each time subtracting the bootstrapped control median from the bootstrapped treat median. So, values above 0 indicate the treatment is more effective (at lengthening teeth) than the control. \n\nLet's look at this distribution\n\n\n```{r}\ntibble(bs_diffs_median = bs_diff_meds) |>\n    ggplot(aes(x=bs_diffs_median)) +\n    geom_histogram() +\n    geom_vline(xintercept = 0) + \n    geom_vline(\n        xintercept = median(treatment_toothlengths) - median(control_toothlengths), linetype = \"dashed\", colour = \"green\"         \n        ) + \n    labs(\n       x = \"Differences in medians\",\n       y = \"Number of bootstraps\",\n       title = \"Bootstrapping approach Two\",\n       subtitle = \"Values above 0: medians are higher in treatment group\"\n    )\n\n```\n\nI've added the observed difference in medians as a vertical green line. This corresponds with the highest peak in bootstrapped differences in medians, as we might expect. \n\n*Almost* all bootstrapped differences in medians are above 0, which again suggests we don't even need to calculate the proportion above 0 to work out if there is likely to be a difference in medians between the two groups. \n\nHowever if we wanted to get this empirical p-value, we could do it as follows: \n\n```{r}\nsum(bs_diff_meds < 0) / Nreps\n\n```\n\nTiny! \n\n\n## Going further \n\nI suggested to Neil that writing some R code to do the bootstrapping can be a 'good' learning experience. This is what I've done in the above, using for loops as they're easiest to reason through, even though not the most computationally efficient. Once the intuition of what bootstrapping is, how it works, and what it can do is embedded through writing out a few examples like this, there are plenty of packages that make bootstrapping even easier to do (and likely faster to run too). \n\nI also mentioned and can (for pedagogic purposes) recommend [the infer package](https://infer.netlify.app/), which uses bootstrapping to produce estimates of distributions under the Null hypothesis, alongside parametric approaches, and produces pretty visualisations to boot! \n\n"},"formats":{"html":{"identifier":{"display-name":"HTML","target-format":"html","base-format":"html"},"execute":{"fig-width":7,"fig-height":5,"fig-format":"retina","fig-dpi":96,"df-print":"default","error":false,"eval":true,"cache":null,"freeze":false,"echo":true,"output":true,"warning":true,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":null,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"engine":"knitr"},"render":{"keep-tex":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"html","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":"none","code-overflow":"scroll","code-link":false,"code-line-numbers":false,"code-tools":false,"tbl-colwidths":"auto","merge-includes":true,"inline-includes":false,"preserve-yaml":false,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[],"notebook-links":true,"format-links":true},"pandoc":{"standalone":true,"wrap":"none","default-image-extension":"png","to":"html","css":["../../../styles.css"],"toc":true,"output-file":"index.html"},"language":{"toc-title-document":"Table of contents","toc-title-website":"On this page","related-formats-title":"Other Formats","related-notebooks-title":"Notebooks","source-notebooks-prefix":"Source","section-title-abstract":"Abstract","section-title-appendices":"Appendices","section-title-footnotes":"Footnotes","section-title-references":"References","section-title-reuse":"Reuse","section-title-copyright":"Copyright","section-title-citation":"Citation","appendix-attribution-cite-as":"For attribution, please cite this work as:","appendix-attribution-bibtex":"BibTeX citation:","title-block-author-single":"Author","title-block-author-plural":"Authors","title-block-affiliation-single":"Affiliation","title-block-affiliation-plural":"Affiliations","title-block-published":"Published","title-block-modified":"Modified","callout-tip-title":"Tip","callout-note-title":"Note","callout-warning-title":"Warning","callout-important-title":"Important","callout-caution-title":"Caution","code-summary":"Code","code-tools-menu-caption":"Code","code-tools-show-all-code":"Show All Code","code-tools-hide-all-code":"Hide All Code","code-tools-view-source":"View Source","code-tools-source-code":"Source Code","code-line":"Line","code-lines":"Lines","copy-button-tooltip":"Copy to Clipboard","copy-button-tooltip-success":"Copied!","repo-action-links-edit":"Edit this page","repo-action-links-source":"View source","repo-action-links-issue":"Report an issue","back-to-top":"Back to top","search-no-results-text":"No results","search-matching-documents-text":"matching documents","search-copy-link-title":"Copy link to search","search-hide-matches-text":"Hide additional matches","search-more-match-text":"more match in this document","search-more-matches-text":"more matches in this document","search-clear-button-title":"Clear","search-detached-cancel-button-title":"Cancel","search-submit-button-title":"Submit","search-label":"Search","toggle-section":"Toggle section","toggle-sidebar":"Toggle sidebar navigation","toggle-dark-mode":"Toggle dark mode","toggle-reader-mode":"Toggle reader mode","toggle-navigation":"Toggle navigation","crossref-fig-title":"Figure","crossref-tbl-title":"Table","crossref-lst-title":"Listing","crossref-thm-title":"Theorem","crossref-lem-title":"Lemma","crossref-cor-title":"Corollary","crossref-prp-title":"Proposition","crossref-cnj-title":"Conjecture","crossref-def-title":"Definition","crossref-exm-title":"Example","crossref-exr-title":"Exercise","crossref-ch-prefix":"Chapter","crossref-apx-prefix":"Appendix","crossref-sec-prefix":"Section","crossref-eq-prefix":"Equation","crossref-lof-title":"List of Figures","crossref-lot-title":"List of Tables","crossref-lol-title":"List of Listings","environment-proof-title":"Proof","environment-remark-title":"Remark","environment-solution-title":"Solution","listing-page-order-by":"Order By","listing-page-order-by-default":"Default","listing-page-order-by-date-asc":"Oldest","listing-page-order-by-date-desc":"Newest","listing-page-order-by-number-desc":"High to Low","listing-page-order-by-number-asc":"Low to High","listing-page-field-date":"Date","listing-page-field-title":"Title","listing-page-field-description":"Description","listing-page-field-author":"Author","listing-page-field-filename":"File Name","listing-page-field-filemodified":"Modified","listing-page-field-subtitle":"Subtitle","listing-page-field-readingtime":"Reading Time","listing-page-field-categories":"Categories","listing-page-minutes-compact":"{0} min","listing-page-category-all":"All","listing-page-no-matches":"No matching items"},"metadata":{"lang":"en","fig-responsive":true,"quarto-version":"1.3.450","theme":"cosmo","title":"A brief introduction to bootstrapping","subtitle":"(It's only literally like pulling teeth, and only in this specific example!)","author":"Jon Minton","date":"2024-06-28","resampling-order":2,"categories":["bootstrapping","statistics","non-parametric"]},"extensions":{"book":{"multiFile":true}}}},"projectFormats":["html"]}